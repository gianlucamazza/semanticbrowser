# Semantic Browser Development Environment Configuration
# This file contains development-friendly defaults for local Docker development
#
# ⚠️ DEVELOPMENT ONLY - DO NOT USE IN PRODUCTION
# - Uses weak JWT secret for convenience
# - Enables verbose logging
# - Disables certain security features
# - Uses local services (Ollama, Redis)
#
# Usage:
#   docker-compose -f docker/docker-compose.dev.yml --env-file docker/.env.dev up

# ==============================================================================
# Development Mode
# ==============================================================================
DEVELOPMENT_MODE=true

# ==============================================================================
# JWT Authentication (WEAK SECRET - DEV ONLY)
# ==============================================================================
# DO NOT USE THIS SECRET IN PRODUCTION
JWT_SECRET=dev-secret-key-min-32-chars-1234567890abcdef

# ==============================================================================
# LLM Configuration - Ollama (Local, No API Key Required)
# ==============================================================================
# Ollama runs as a container service in docker-compose.dev.yml
# Default endpoint points to the ollama service container
OLLAMA_API_BASE=http://ollama:11434

# Default model to use (make sure to pull it first)
# Pull with: docker exec semantic-browser-ollama-dev ollama pull llama3.2
# Available models:
# - llama3.2 (8B, latest) - Best balance of speed and quality
# - llama3.2:1b - Fastest, good for testing
# - mistral:latest - Alternative, good performance
# - codellama:latest - Optimized for code tasks
OLLAMA_MODEL=llama3.2:latest

# ==============================================================================
# Redis Configuration
# ==============================================================================
# Redis runs as a container service in docker-compose.dev.yml
REDIS_URL=redis://redis:6379

# ==============================================================================
# Logging Configuration - VERBOSE for Development
# ==============================================================================
# Trace-level logging for semantic_browser, debug for dependencies
RUST_LOG=debug,semantic_browser=trace,tower_http=debug

# Show full backtraces on panic
RUST_BACKTRACE=full

# ==============================================================================
# Machine Learning Models (OPTIONAL)
# ==============================================================================
# Paths are relative to the container's /models directory
# Mount your models from host: ../models:/models:ro

# NER Model Configuration
# NER_MODEL_PATH=/models/ner-model.onnx
# NER_TOKENIZER_PATH=/models/tokenizer.json
# NER_LABELS_PATH=/models/labels.txt

# Knowledge Graph Inference Model
# KG_INFERENCE_MODEL_PATH=/models/kg-inference-model.onnx
# KG_EMBEDDING_TYPE=TransE
# KG_INFERENCE_CONFIDENCE_THRESHOLD=0.7
# KG_INFERENCE_TOP_K=5

# ==============================================================================
# Knowledge Graph Persistence
# ==============================================================================
# Persistent storage for development KG data
KG_PERSIST_PATH=/data/kg

# ==============================================================================
# Browser Automation Configuration
# ==============================================================================
# Run browser in headless mode (set to false to see browser window)
# Note: In Docker, you typically want headless=true
BROWSER_HEADLESS=true

# Navigation timeout in seconds (generous for development)
BROWSER_TIMEOUT_SECS=60

# Maximum number of concurrent browser tabs
BROWSER_POOL_SIZE=2

# Block ads and trackers (improves speed)
BLOCK_ADS=true

# Block images for text-only extraction (faster)
# BLOCK_IMAGES=false

# Chromium path (auto-detected in container)
# CHROMIUM_PATH=/usr/bin/chromium

# ==============================================================================
# API Server Configuration
# ==============================================================================
# Server bind address and port
SERVER_ADDR=0.0.0.0
SERVER_PORT=3000

# ==============================================================================
# Security Configuration (RELAXED for Development)
# ==============================================================================
# Disable strict security mode in development
SECURITY_STRICT_MODE=false

# Maximum HTML input size in bytes (10 MB)
MAX_HTML_SIZE=10000000

# Maximum SPARQL query length
MAX_QUERY_LENGTH=10000

# ==============================================================================
# Rate Limiting Configuration (RELAXED for Development)
# ==============================================================================
# High limits for local development
RATE_LIMIT_REQUESTS_PER_MINUTE=600
RATE_LIMIT_BURST_SIZE=100

# ==============================================================================
# Monitoring and Metrics (OPTIONAL)
# ==============================================================================
# Enable Prometheus metrics for development monitoring
# PROMETHEUS_METRICS=true
# METRICS_PORT=9090

# OpenTelemetry configuration (if using)
# OTEL_SERVICE_NAME=semantic-browser-dev
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# ==============================================================================
# External Service API Keys (OPTIONAL - For Testing OpenAI/Anthropic)
# ==============================================================================
# If you want to test against real OpenAI/Anthropic APIs, add your keys here
# Otherwise, use Ollama (no key required)

# OpenAI API Key (optional, for testing only)
# OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Key (optional, for testing only)
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# GitHub Token (for api_client_example.rs)
# GITHUB_TOKEN=ghp_your-github-token-here

# Hugging Face Token (for model downloads)
# HUGGINGFACE_TOKEN=hf_your-huggingface-token-here

# ==============================================================================
# Data Paths (Container Paths)
# ==============================================================================
# These paths are inside the container
# Host paths are configured in docker-compose.dev.yml volumes section
KG_DATA_PATH=./data/kg-dev

# ==============================================================================
# Development Tips
# ==============================================================================
# 1. Start services: docker-compose -f docker/docker-compose.dev.yml up
# 2. View logs: docker-compose -f docker/docker-compose.dev.yml logs -f
# 3. Pull Ollama model: docker exec semantic-browser-ollama-dev ollama pull llama3.2
# 4. Access Redis CLI: docker exec -it semantic-browser-redis-dev redis-cli
# 5. Shell into app: docker exec -it semantic-browser-dev bash
# 6. Rebuild app: docker-compose -f docker/docker-compose.dev.yml build semantic_browser
#
# Hot Reload:
# - Edit files in src/
# - cargo-watch automatically rebuilds
# - Container restarts service automatically
#
# Quick Test:
# - curl http://localhost:3000/
# - Check health: curl http://localhost:3000/health
# - Redis ping: docker exec semantic-browser-redis-dev redis-cli ping
# - Ollama list: docker exec semantic-browser-ollama-dev ollama list
